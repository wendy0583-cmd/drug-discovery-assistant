"""
ë¹ ë¥¸ ë³´ê³ ì„œ ìƒì„± ëª¨ë“œ (5ë¶„ ì´ë‚´)
- ë³‘ë ¬ ê²€ìƒ‰
- ê²°ê³¼ ê°œìˆ˜ ì œí•œ
- ê°„ë‹¨í•œ ìš”ì•½
"""

from strands import Agent, tool
from strands.models import BedrockModel
from botocore.config import Config
import logging
import asyncio
from concurrent.futures import ThreadPoolExecutor
import sys

logging.basicConfig(
    level=logging.INFO,
    format='%(filename)s:%(lineno)d | %(message)s',
    handlers=[
        logging.StreamHandler(sys.stderr)
    ]
)
logger = logging.getLogger("chat_fast")

def get_fast_model():
    """ë¹ ë¥¸ Nova Micro ëª¨ë¸ ì‚¬ìš©"""
    model = BedrockModel(
        boto_client_config=Config(
            read_timeout=300,
            connect_timeout=300,
            retries=dict(max_attempts=2, mode="adaptive"),
        ),
        model_id="us.amazon.nova-micro-v1:0",
        max_tokens=2000,  # ì§§ì€ ì‘ë‹µ
        temperature=0.3,
    )
    return model

@tool
def fast_search_all_databases(query: str, max_results: int = 3) -> str:
    """
    ëª¨ë“  ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ë³‘ë ¬ë¡œ ë¹ ë¥´ê²Œ ê²€ìƒ‰
    
    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        max_results: ê° DBë‹¹ ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ 3ê°œ)
    
    Returns:
        í†µí•© ê²€ìƒ‰ ê²°ê³¼
    """
    
    results = {
        "arxiv": "ê²€ìƒ‰ ì¤‘...",
        "pubmed": "ê²€ìƒ‰ ì¤‘...",
        "chembl": "ê²€ìƒ‰ ì¤‘...",
        "clinicaltrials": "ê²€ìƒ‰ ì¤‘..."
    }
    
    # ì‹¤ì œë¡œëŠ” MCP í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë³‘ë ¬ ê²€ìƒ‰
    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ êµ¬ì¡°ë§Œ ì œì‹œ
    
    output = f"""
=== ë¹ ë¥¸ ê²€ìƒ‰ ê²°ê³¼ (ê° DBë‹¹ ìµœëŒ€ {max_results}ê°œ) ===

ğŸ“š arXiv: {results['arxiv']}
ğŸ¥ PubMed: {results['pubmed']}
ğŸ§ª ChEMBL: {results['chembl']}
ğŸ”¬ ClinicalTrials: {results['clinicaltrials']}
"""
    
    return output

@tool
def generate_fast_report(query: str, search_results: str) -> str:
    """
    ë¹ ë¥¸ ë³´ê³ ì„œ ìƒì„± (ìš”ì•½ë³¸)
    
    Args:
        query: ì›ë³¸ ì§ˆë¬¸
        search_results: ê²€ìƒ‰ ê²°ê³¼
    
    Returns:
        ê°„ë‹¨í•œ ë³´ê³ ì„œ
    """
    
    model = get_fast_model()
    
    prompt = f"""
ë‹¤ìŒ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ 1í˜ì´ì§€ ë¶„ëŸ‰ì˜ ê°„ë‹¨í•œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.

ì§ˆë¬¸: {query}

ê²€ìƒ‰ ê²°ê³¼:
{search_results}

ë³´ê³ ì„œ êµ¬ì„±:
1. í•µì‹¬ ìš”ì•½ (3-5ë¬¸ì¥)
2. ì£¼ìš” ë°œê²¬ì‚¬í•­ (3-5ê°œ bullet points)
3. ì°¸ê³ ë¬¸í—Œ (3-5ê°œ)

ê°„ê²°í•˜ê³  í•µì‹¬ë§Œ ë‹´ì•„ì£¼ì„¸ìš”.
"""
    
    agent = Agent(
        model=model,
        system_prompt="ë‹¹ì‹ ì€ ê³¼í•™ ë³´ê³ ì„œë¥¼ ë¹ ë¥´ê³  ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
    )
    
    response = agent(prompt)
    return str(response)

def run_fast_report(question: str) -> str:
    """
    5ë¶„ ì´ë‚´ ë¹ ë¥¸ ë³´ê³ ì„œ ìƒì„±
    
    Args:
        question: ì‚¬ìš©ì ì§ˆë¬¸
    
    Returns:
        ë³´ê³ ì„œ ë‚´ìš©
    """
    
    logger.info(f"ë¹ ë¥¸ ë³´ê³ ì„œ ìƒì„± ì‹œì‘: {question}")
    
    # 1ë‹¨ê³„: ë¹ ë¥¸ ê²€ìƒ‰ (ë³‘ë ¬)
    search_results = fast_search_all_databases(question, max_results=3)
    
    # 2ë‹¨ê³„: ë¹ ë¥¸ ë³´ê³ ì„œ ìƒì„±
    report = generate_fast_report(question, search_results)
    
    logger.info("ë¹ ë¥¸ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")
    
    return report
